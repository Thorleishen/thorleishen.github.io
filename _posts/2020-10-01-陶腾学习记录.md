## 学习笔记之一



[TOC]



1. mysql查询数据库名和查询数据库对应的表名

   ```mysql
   -- 查询某数据库中所有表
   select count(*) from information_schema.TABLES t where t.TABLE_SCHEMA ="数据库名" and t.TABLE_NAME ="数据库表名";
   -- 模糊查询某数据库中的表
   select count(*) from information_schema.TABLES t where t.TABLE_SCHEMA ="数据库名" and t.TABLE_NAME like "%数据库表名%";
   ```

2. mysql聚合查询报错

   ```mysql
   select count(*) from (select * from dede_spacemoney group by sid) ;
   -- 当我执行到这里的时候就抛出了这个异常，原来我进行嵌套查询的时候子查询出来的的结果是作为一个派生表来进行上一级的查询的，所以子查询的结果必须要有一个别名
   
   -- 把MySQL语句改成：
   select count(*) from (select * from list where name="xiao") as t;
   
   -- 问题就解决了，虽然只加了一个没有任何作用的别名t，但这个别名是必须的！
   ```

3. 查询数据库表结构大小

   ```mysqL
   -- 1、进入information_schema 数据库（存放了其他的数据库的信息）
   
   use information_schema;
   
      
   
   -- 2、查询所有数据的大小：
   
   select concat(round(sum(data_length/1024/1024),2),'MB') as data from tables;
   
      
   
   -- 3、查看指定数据库的大小：比如查看数据库home的大小
   
   select concat(round(sum(data_length/1024/1024),2),'MB') as data from tables where table_schema='home';
   
      
   
   -- 4、查看指定数据库的某个表的大小，比如查看数据库home中 members 表的大小
   
   select concat(round(sum(data_length/1024/1024),2),'MB') as data from tables where table_schema='home' and table_name='members';
   ```

   

数据库5.7安装：https://www.cnblogs.com/fanshudada/p/9781794.html



#### 第一周2020/4/27-2020/5/3

```python
# pymongo操作mongodb数据库，使用skip和limit方法
# 问题：使用count方法时得不到准确的数据条数
# 解决办法
db.dbname.find().skip().limit().count(True)
```



#### 第二周2020/5/6-2020/5/9

```mysql
# 问题：解决多台服务器操作同一个mysql数据库，其中一台服务器对mysql进行增删改操作，其他服务器查询不到增删改后的数据，还是查询到的是以往的数据
# 类似问题：使用pymysql进行定时查询（不关闭数据库），定时插入数据，pymysql再次查询的数据不更新
# 原因：
REPEATABLE READ
The default isolation level for InnoDB. It prevents any rows that are queried from being
changed by other transactions, thus blocking non-repeatable reads but not phantom reads.
It uses a moderately strict locking strategy so that all queries within a transaction see
data from the same snapshot, that is, the data as it was at the time the transaction started.
重复读
innodb的默认隔离级别。它防止查询的任何行
由其他事务更改，因此阻止不可重复的读取，但不阻止幻象读取。
它使用适度严格的锁定策略，以便事务中的所有查询都可以看到
来自同一快照的数据，即事务启动时的数据。
# 解决办法：每次执行查询操作时，更新查询事务
db.cursor.execute(sql)
db.cursor.fetchall()
db.conn.commit() # 更新查询事务

# 应用场景
# 在需要使用事务的情况下选择innodb引擎
```

#### 第三周2020/5/11-2020/5/15

```mysql
# 插入数据，若唯一键冲突则更新数据
 insert into table (xxx, xxx) values(xxx,xxx), (xxx, xxx) on duplicate key update xxx=values(xxx),xxx=values(xxx);
 # ignore	关键字
 # 唯一键如果冲突则跳过不插入
 insert ignore into table (xxx, xxx) values (xxx,xxx), (xxx, xxx);
 # Replace Into
 # 唯一键冲突会删除冲突数据插入新数据
 replace into table (xxx, xxx) values (xxx,xxx), (xxx, xxx);
```

#### 第四周2020/5/18-2020/5/22

本周修改BUG

#### 第五周2020/5/25-2020/5/29

1. 类（继承、封装、多态）

2. python下划线使用场景

3. pep8规范

4. python 虚拟环境安装

   ```python
   # 安装虚拟环境
   pip install pip install virtualenv virtualenvwrapper -i https://douban.pypi.com/simple
   # 设置环境变量 
   vi ~.bash_profile
   # 添加如下配置
   export WORKON_HOME=~/Envs   #设置virtualenv的统一管理目录
   export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages'   #添加virtualenvwrapper的参数，生成干净隔绝的环境
   export VIRTUALENVWRAPPER_PYTHON=/usr/local/python3/bin/python3     #指定python解释器
   source /usr/local/python3/bin/virtualenvwrapper.sh #执行virtualenvwrapper安装脚本
   # 使配置生效
   source ~.bash_profile
   # 如果遇到报错：virtualenv: error: unrecognized arguments: --no-site-packages
   # 问题原因: virtualenv版本问题
   # 解决方案: 指定版本安装
   pip uninstall virtualenv
   pip install virtualenv==16.7.9
   ```

#### 第六周2020/6/1-2020/6/5

1. nginx反向代理

   ```nginx
   # 由于目前数据收集和数据展示在同一个服务端里面，由于数据收集并发量比较大，导致数据展示API请求时缓慢，需要将数据收集和数据展示分离，目前url前缀为sdk为数据收集，datashow为数据展示API
   # nginx 通过配置location反向代理到相应的服务器
   location /datashow/ {
     proxy_pass http://apis;
   } # 反向代理到数据展示API
   location /sdk/ {
     proxy_pass http://datashows;  # 注：datashows 后面没有/，如果加/则会反向代理到sdk后面的uri,例：http:domain/sdk/report/index会反向代理到/report/index，不加/则会代理到/sdk/report/index
   } # 反向代理到数据收集
   ```

2. mongodb主从配置

   ```mongodb
   # mongodb4.0以后不在支持主从配置
   # 报错:  Master/slave replication is no longer supported
   # 使用Replica Sets记录之
   # 参考🔗:https://mongoing.com/archives/38481   https://docs.mongodb.com/manual/core/replica-set-architectures/
   ```

3. tornado异步非阻塞请求

   ```python
   # 协程的使用，使用协程的上下文管理器，当遇到IO阻塞时，会处理其他请求，等到IO成功后，返回到之前的状态
   @tornado.web.asynchronous
   @tornado.gen.coroutine
   ```

4. web前端更新页面后如何在客户端检测并刷新缓存

   ```html
   # css、js在浏览器中存在过期时间，但过期时间没有过期，会一直使用旧的css、js
   # 解决方案
   # 通过给css文件、js文件提供一个版本号，当下一改动，更新最新的版本号，浏览器检测到该css、js文件不是最新的文件会自动刷新浏览器缓存文件
   1. 更改css、js文件名方法
   <link rel="stylesheet" href="index.v2011.css" />
   更改后:
   <link rel="stylesheet" href="index.v2012.css" />
   2. css文件加个版本号
   <link rel="stylesheet" href="style.css?v=2011" />
   更改后:
   <link rel="stylesheet" href="style.css?v=2012" />
   
   注: 部分代理缓存服务器不会缓存网址中包含 "?" 的资源，所以方法二可能会导致你原先的缓存功能失效，可以改用第一种方法；其实css文件后面的问号起不到实际作用，仅能当作后缀，如果用问号加参数的方法，可以添加版本号等信息，同时可以刷新一下浏览器端的缓存。一个小小的细节，可以给我们带来很大的方便
   ```

#### 第七周2020/6/8-2020/6/12

1. mongodb超时问题

   ```mysql
   # 由于数据量过大导致mongodb超时问题
   # pymongo操作mongodb数据
   # 解决方案1 使cursor游标永不超时
   mongo.db["***"].find({}, {}, no_cursor_timeout=True)
   # 解决方案2 游标不超时并分组执行
   mongo.db["***"].find({}, {}, no_cursor_timeout=True).batch_size(500)
   ```

2. tornado请求超时问题

   ```
   # 问题分析: 由于遇到比较耗时的操作，导致http请求阻塞在IO读写上面
   # 解决方案: 1. 将耗时的IO操作单独提取出来；2. 使用tornado异步非阻塞请求
   ```

3. rabbitMQ消息队列中间件安装

   ```shell
   # centos8安装方法
   # 第一步：安装erlang语言（注: 需要和rabbitMQ版本对应，具体请求查看链接:https://www.rabbitmq.com/which-erlang.html）
   # 依赖环境
   yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel
   yum -y install ncurses-devel
   # yum 安装
   yum install erlang
   # 使用源码安装，链接地址: https://erlang.org/download/otp_src_22.1.tar.gz
   #创建目录(名字随便，能找到就行)
   mkdir /usr/local/erlang
   #进入目录准备下载
   cd /usr/local/erlang/
   #开始下载
   wget https://erlang.org/download/otp_src_22.1.tar.gz
   tar -zxvf otp_src_22.1.tar.gz 
   #进入解压目录
   cd otp_src_22.1/
   #安装,注意目录位置
   ./configure --prefix=/usr/local/erlang/otp_src_22.1/ --with-ssl --enable-hipe --enable-threads --enable-smp-support --enable-kernel-poll --without-javac
   #编译&&安装
   make && make install
   #设置环境变量（按a输入，按esc  输入：wq保存，q不保存）
   vim /etc/profile
   #加入一条：
   export PATH=$JAVA_HOME/bin/:$PATH:/usr/local/erlang/otp_src_22.1/bin:$PATH
   #让配置生效
   source /etc/profile
   #查看erlang是否安装成功
   erl
   
   # 第二步: 安装socat
   # 先执行
   yum install socat
   # 如果没有rpm文件则执行以下
   wget http://repo.iotti.biz/CentOS/6/x86_64/socat-1.7.3.2-1.el6.lux.x86_64.rpm
   rpm -ivh socat-1.7.3.2-1.el6.lux.x86_64.rpm
   yum install socat-1.7.3.2-1
   
   # 第三步: 安装rabbitmq
   # 官方https://www.rabbitmq.com/install-rpm.html#package-dependencies
   yum install rabbitmq-server-3.8.4-1.el7.noarch.rpm 
   # 启动web管理页面
   rabbitmq-plugins enable rabbitmq_management （http://127.0.0.1:15672）
   # 后台启动
   rabbitmq-server -detached
   # 查看当前所有用户
   rabbitmqctl list_users
   # 查看默认guest用户的权限
   rabbitmqctl list_user_permissions guest
   # 由于RabbitMQ默认的账号用户名和密码都是guest。为了安全起见, 先删掉默认用户
   rabbitmqctl delete_user guest
   # 添加新用户
   rabbitmqctl add_user username password
   # 设置用户tag
   rabbitmqctl set_user_tags username administrator
   # 赋予用户默认vhost的全部操作权限
   rabbitmqctl set_permissions -p / username ".*" ".*" ".*"
   # 查看用户的权限
   rabbitmqctl list_user_permissions username
   # 注意： 15672端口是连接rabbitmq用的
   
   # 注: centos7 erlang版本为5.10.4，请根据实际erlang版本安装兼容的rabbitmq
   ```

4. supervisor安装

   ```shell
   # 安装
   yum install supervisor
   pip install supervisor
   # 编辑配置文件
   vi /etc/supervisord.conf
   ```

#### 第八周2020/6/15-2020/6/20

1. rabbitmq内存优化配置

   ```shell
    # 实际问题: rabbitmq队列超出实例服务器可用RAM大小，导致rabbitmq在没有到达最大分页阈值时就已经挂掉
    # 解决方案: 通过设置rabbitmq最大内存值控制最大分页阈值
    # 当rabbitmq运行时设置
    rabbitmqctl set_vm_memory_high_watermark 0.4
    # 内存计算过程
    # rabbitmq最大内存vm_memory_high_watermark，默认为服务器RAM的0.4，最大分页内存vm_memory_high_watermark_paging_ratio默认为最大内存vm_memory_high_watermark的0.5
    # vm_memory_high_watermark = RAM * 0.4
    # vm_memory_high_watermark_paging_ratio = RAM * 0.4 * 0.5
    # 参考链接: https://www.rabbitmq.com/memory.html
   ```

2. mongodb内存占用过高问题

   ```shell
   # mongodb3.4开始，默认使用WiredTiger引擎，WiredTiger将用于所有数据的内部缓存的最大大小，索引构建消耗的内存 与WiredTiger缓存内存是分开的；值的范围可以从0.25GB到10000GB
   # 内存大小：50％（RAM-1 GB 或 256 MB；内存小于256MB则内存为256MB
   # 内存配置
   # mongodb.conf文件中配置 wiredTigerCacheSizeGB = 2
   # 命令行配置 --wiredTigerCacheSizeGB <float>
   # 重启mongodb，不要使用kill + mongodbPID，以下为正确操作
   use admin
   db.shutdownServer()
   ```

3. email、smtplib发送邮件

   ```python
   #!/usr/bin/python
   # -*- coding: UTF-8 -*-
    
   import smtplib
   from email.mime.text import MIMEText
   from email.header import Header
    
   # 第三方 SMTP 服务
   mail_host="smtp.XXX.com"  #设置服务器
   mail_user="XXXX"    #用户名
   mail_pass="XXXXXX"   #授权吗 
   
   sender = 'from@runoob.com'
   receivers = ['429240967@qq.com']  # 接收邮件，可设置为你的QQ邮箱或者其他邮箱
    
   message = MIMEText('Python 邮件发送测试...', 'plain', 'utf-8')
   message['From'] = Header("sender<from@runoob.com>", 'utf-8')
   message['To'] =  Header("admin<429240967@qq.com>", 'utf-8')
    
   subject = 'Python SMTP 邮件测试'
   message['Subject'] = Header(subject, 'utf-8')
   
   try:
       smtpObj = smtplib.SMTP() 
       smtpObj.connect(mail_host, 25)    # 25 为 SMTP 端口号
       # smtpObj = smtplib.SMTP_SSL(mail_host)  # 使用SSL端口号登录
       smtpObj.login(mail_user,mail_pass)  
       smtpObj.sendmail(sender, receivers, message.as_string())
       print "邮件发送成功"
   except smtplib.SMTPException:
       print "Error: 无法发送邮件"
       
   # 注: 554报错，邮件发件人From和收件人To的格式需要改为'admin<429240967@qq.com>;user<1111111@qq.com>'
   ```


#### 第九周2020/6/22-2020/6/26

1. Redis 缓存

   ```
   pass
   ```

2. git表情

   | emoji            | emoji代码                  | commit 说明           |
   | ---------------- | -------------------------- | --------------------- |
   | ? (调色板)       | :art:                      | 改进代码结构/代码格式 |
   | ⚡️ (闪电)? (赛马) | :zap:“:racehorse:          | 提升性能              |
   | ? (火焰)         | :fire:                     | 移除代码或文件        |
   | ? (bug)          | :bug:                      | 修复 bug              |
   | ? (急救车)       | :ambulance:                | 重要补丁              |
   | ✨ (火花)         | :sparkles:                 | 引入新功能            |
   | ? (备忘录)       | :memo:                     | 撰写文档              |
   | ? (火箭)         | :rocket:                   | 部署功能              |
   | ? (口红)         | :lipstick:                 | 更新 UI 和样式文件    |
   | ? (庆祝)         | :tada:                     | 初次提交              |
   | ✅ (白色复选框)   | :white_check_mark:         | 增加测试              |
   | ? (锁)           | :lock:                     | 修复安全问题          |
   | ? (苹果)         | :apple:                    | 修复 macOS 下的问题   |
   | ? (企鹅)         | :penguin:                  | 修复 Linux 下的问题   |
   | ? (旗帜)         | :checked_flag:             | 修复 Windows 下的问题 |
   | ? (书签)         | :bookmark:                 | 发行/版本标签         |
   | ? (警车灯)       | :rotating_light:           | 移除 linter 警告      |
   | ? (施工)         | :construction:             | 工作进行中            |
   | ? (绿心)         | :green_heart:              | 修复 CI 构建问题      |
   | ⬇️ (下降箭头)     | :arrow_down:               | 降级依赖              |
   | ⬆️ (上升箭头)     | :arrow_up:                 | 升级依赖              |
   | ? (工人)         | :construction_worker:      | 添加 CI 构建系统      |
   | ? (上升趋势图)   | :chart_with_upwards_trend: | 添加分析或跟踪代码    |
   | ? (锤子)         | :hammer:                   | 重大重构              |
   | ➖ (减号)         | :heavy_minus_sign:         | 减少一个依赖          |
   | ? (鲸鱼)         | :whale:                    | Docker 相关工作       |
   | ➕ (加号)         | :heavy_plug_sign:          | 增加一个依赖          |
   | ? (扳手)         | :wrench:                   | 修改配置文件          |
   | ? (地球)         | :globe_with_meridians:     | 国际化与本地化        |
   | ✏️ (铅笔)         | :pencil2:                  | 修复 typo             |

#### 第十周2020/6/29-2020/7/3

1. nginx图片过滤器HttpImageFilter

   ```nginx
   # http_image_filter_module是nginx提供的集成图片处理模块，支持nginx-0.7.54以后的版本，在网站访问量不是很高磁盘有限不想生成多余的图片文件的前提下，就可以用它实时缩放图片，旋转图片，验证图片有效性以及获取图片宽高以及图片类型信息，由于是即时计算的结果，所以网站访问量大的话，不建议使用
   # 安装
   # yum install gd-devel
   --with-http_image_filter_module  # 命令参数
   
   # 指令
   image_filter  # 过滤JPEG、GIF、PNG图片并设置或者裁剪图片大小
   image_filter_buffer  # 设置读取图片的最大尺寸、默认1m
   image_filter_jpeg_quality  # 设置图片作为JPEG处理时的信息丢失率、默认75、最大95
   image_filter_transparency  # 
   ```

2. nginx配置文件上传大小

   ```nginx
   client_max_body_size 1024M;  # 上传文件大小限制
   sendfile on;  # 设置为on表示启动高效传输文件的模式
   keepalive_timeout 1800;  # 保持连接的时间，默认65s
   ```

3. nginx防盗链

   ```nginx
   # 原因，本地服务器静态文件如图片等可以被其他服务器随意访问
   # 防盗链原理: 根据访问referen的域名是否和本机域名一样，不一样则重定向到错误页面等，也可以对某些域名跳过验证
   valid_referers none blocked server_name *.test.com ;  # 对这些域名的网站不进行防盗链，多个地址空格隔开
   ```

4. oss对象存储服务

   ```shell
   # 定义：对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以通过调用 API，在任何应用、任何时间、任何地点上传和下载数据，也可以通过 Web 控制台对数据进行简单的管理
   # 使用场景海量图片、视频静态资源下载等，可生成动态链接访问静态资源并设置过期时间
   ```

#### 第十一周2020/7/6-2020/7/10

1. redis缓存问题

   ```
   1. 缓存雪崩
   原因：在某一时刻，有多个缓存过期，此时需要从DB中获取数据，如果在高并发量服务器上，此时DB的压力会很大，很可能造成服务器挂掉
   解决方案：可以对不同的key值设置不同的过期时间，使缓存过期时间尽量均匀分布
   2. 缓存穿透
   原因：当客户端访问某一缓存时，如果缓存层和DB层都没有查询到数据，此时压力就会在DB层，如果一直对该缓存进行查询，则会出现很严重的后果
   解决方案：对于DB层也没有的数据，也设置缓存，对应的value为空指处理，并设置较短的过期时间
   3. 缓存击穿
   原因：在高并发请求下，某一时刻一个热点缓存过期，此时压力会在DB层，并且同时对该热点进行写操作
   解决方案：在写入缓存的时候加锁
   ```

2. redis持久化设置

   ```
   # redis 持久化有两中，一种是RDB、一种是AOF
   1. RDB文本为redis数据库某一时刻的快照压缩文件，可以通过手动和自动来进行备份
   手动: 在终端命令中输入save命令即开始备份数据，会阻塞服务器，此时服务器不会执行任何操作
   自动：在终端命令中输入bgsave命令，此时redis会使用fork开启一个进程进行数据备份，不会阻塞服务器
   2. AOF文件存储的是各种命令，对于重复的命令，AOF内部有一个重制机制，去除重复的操作
   开启AOF数据备份后，redis间隔一段时间对数据以命令的形式保存到临时文件中同时会fork一个新进程对文件进行重写
   ```

3. rabbitmq的exchange和queue

   ```
   1. exchange类型
   1) direct 默认
   直接交换器，对routing路由进行完全匹配
   2）fanout
   广播式交换器，将消息转发给绑定路由的队列
   3）topic
   主题交换器，将消息转发给匹配路由成功的队列
   4）headers
   消息体header匹配
   
   2. queue类型
   1）持久化队列，queue中的消息会在server本地磁盘存储一份，防止系统crash，数据丢失
   2）临时队列，queue中的消息在服务重启后就会丢失
   3）自动删除的队列，当不存在用户连接到server，队列中的数据会被自动删除
   ```


#### 第十二周2020/7/12-2020/7/17

1. 查看内存前十的进程

   ```shell
   # 服务器突然占满，查看主要占用内存的进程
   ps aux | sort -k4,4nr | head -n 10
   ```

#### 第十三周2020/7/20-2020/7/24

1. mongodb日志文件过大问题

   ```shell
   # logpath配置日志参数，会一直往日志文件中追加日志信息，长时间会积累较大的日志信息，占用内存空间
   # 解决方案1：手动，重启一个新的日志文件
   # 解决方案2: 写个脚本，内存到达多少，执行命令重启一个新的日志文件
   # 解决方案3: 给服务器加内存（不太现实，由于公司有点抠，对比potal组），服务器一台，测试机都没有，等一个崩溃，这是留给后人的坑
   db.runCommand({logRotate:1}) # 重启新的日志文件
   ```

2. python 打印异常

   ```python
   # 1. 正常打印异常
   try:
       pass
   except Exception as e:
       logging.error(e)
       
   # 2. traceback 查看异常具体信息
   import traceback
   traceback.print_exc()
   
   # 3. sys模块查看异常信息
   info = sys.exc_info()
   print(info)
   
   # 4. sys获取函数名和行号
   f = sys.exc_info()[2].tb_frame.f_back
   print(f.f_code.co_name, f.f_lineno)
   ```

3. dataclass默认值

   ```python
   # default和default_factory参数将会影响默认值的产生，它们的默认值都是None，意思是调用时如果为指定则产生一个为None的值。其中default是field的默认值，而default_factory控制如何产生值，它接收一个无参数或者全是默认参数的callable对象，然后用调用这个对象获得field的初始值，之后再将default（如果值不是MISSING）复制给callable返回的这个对象
   @dataclass
   class C:
       mylist: List[int] = field(default_factory=list)
   # init参数如果设置为False，表示不为这个field生成初始化操作，dataclass提供了hook——__post_init__供我们利用这一特性，__post_init__在__init__后被调用，我们可以在这里初始化那些需要前置条件的field
   @dataclass
   class C:
       a: int
       b: int
       c: int = field(init=False)
   
       def __post_init__(self):
           self.c = self.a + self.b
   # 如果指定一个field的类型注解为dataclasses.InitVar, 那么这个field将只会在初始化过程中（__init__和__post_init__）可以被使用
   @dataclass
   class C:
       i: int
       j: int = None
       database: InitVar[DatabaseType] = None
   
       def __post_init__(self, database):
           if self.j is None and database is not None:
               self.j = database.lookup('j')
   
   c = C(10, database=my_database)
   ```

4. Super、新式类和经典类

   ```python
   # super获取父类方法，可以调用父类方法
   class A(object):
     
     def __init__(self, a):
       self.a = a
       
   class B(A):
     
     def __init__(self, a, b):
       super(B, self).__init__(a)
       self.b = b
   
   # 新式类和经典类
   # 新式类多继承采用广度优先的方式查找父类，如钻石继承
   # 经典类采用深度优先的方式查找父类
   # cls.mro() 查看父类的顺序
   ```


## 第十五周2020/8/10-2020/8/14

1. 删除数据库阻塞

   ```mysql
   show full processlist;
   # 查看
   ```

2. 页面控制台命令直接修改网页内容

   ```javascript
   document.body.contentEditable = true;
   ```


## 第十七周2020/8/30-2020/9/4

1. mydumper安装及原理

   ```
   # 特性
   1. 使用多线程备份数据，备份后会存在多个备份文件
   2. 备份时对MyISAM表施加FTWRL(FLUSH TABLES WITH READ LOCK),会阻塞DML语句(增删改)
   3. 保证备份数据的一致性
   4. 支持文件压缩、导出binlog文件
   5. 支持多线程恢复
   6. 支持以守护进程模式工作，定时快照和连续二进制日志
   7. 支持将备份文件切块
   
   # 安装
   1. 安装依赖包
   yum install glib2-devel mysql-devel zlib-devel pcre-devel openssl-devel cmake make
   2. 下载二进制包
   wget https://launchpadlibrarian.net/225370879/mydumper-0.9.1.tar.gz
   tar -zxvf mydumper-0.9.1.tar.gz -C /usr/local/  # 解压
   mv mydumper-0.9.1 mydumper  
   cd   /usr/local/mydumper  
   cmake .
   make && make install # 编译
   3. 查看安装是否成功
   mydumper -V
   # 如果报错，mydumper: error while loading shared libraries: libmysqlclient.so.20: cannot open shared object file: No such file or directory,说明缺少mysql依赖文件
   ldd /usr/local/bin/mydumper  # 查看mydumper依赖文件
   cp /usr/local/mysql/lib/libmysqlclient.so.20 /usr/lib/  # 复制mysql中的依赖文件到指定目录
   ldconfig  # 默认往往/lib和/usr/lib里面加东西
   
   4. 备份和恢复
   ###备份单个库 
   mydumper -u root -p ### -h localhost -B game -c -o /backup/01
   ###备份所有数据库，并备份二进制日志文件，备份至 /backup/02 文件夹
   mydumper -u root -p ### -h localhost -o /backup/02
   ###备份 game.tb_player 表，且不备份表结构，备份至 /backup/03 文件夹
   mydumper -u root -p ### -h localhost -T tb_player -m -o /backup/03
   ###压缩协议还原
   myloader -u root -p ### -h localhost -B game -d -C /backup/02
   
   5. 参数
   mydumper 参数
   
   -B, --database              要备份的数据库，不指定则备份所有库
   -T, --tables-list           需要备份的表，名字用逗号隔开
   -o, --outputdir             备份文件输出的目录
   -s, --statement-size        生成的insert语句的字节数，默认1000000
   -r, --rows                  将表按行分块时，指定的块行数，指定这个选项会关闭 --chunk-filesize
   -F, --chunk-filesize        将表按大小分块时，指定的块大小，单位是 MB
   -c, --compress              压缩输出文件
   -e, --build-empty-files     如果表数据是空，还是产生一个空文件（默认无数据则只有表结构文件）
   -x, --regex                 是同正则表达式匹配 'db.table'
   -i, --ignore-engines        忽略的存储引擎，用都厚分割
   -m, --no-schemas            不备份表结构
   -k, --no-locks              不使用临时共享只读锁，使用这个选项会造成数据不一致
   --less-locking              减少对InnoDB表的锁施加时间（这种模式的机制下文详解）
   -l, --long-query-guard      设定阻塞备份的长查询超时时间，单位是秒，默认是60秒（超时后默认mydumper将会退出）
   --kill-long-queries         杀掉长查询 (不退出)
   -b, --binlogs               导出binlog
   -D, --daemon                启用守护进程模式，守护进程模式以某个间隔不间断对数据库进行备份
   -I, --snapshot-interval     dump快照间隔时间，默认60s，需要在daemon模式下
   -L, --logfile               使用的日志文件名(mydumper所产生的日志), 默认使用标准输出
   --tz-utc                    跨时区是使用的选项，不解释了
   --skip-tz-utc               同上
   --use-savepoints            使用savepoints来减少采集metadata所造成的锁时间，需要 SUPER 权限
   --success-on-1146           Not increment error count and Warning instead of Critical in case of table doesn't exist
   -h, --host                  连接的主机名
   -u, --user                  备份所使用的用户
   -p, --password              密码
   -P, --port                  端口
   -S, --socket                使用socket通信时的socket文件
   -t, --threads               开启的备份线程数，默认是4
   -C, --compress-protocol     压缩与mysql通信的数据
   -V, --version               显示版本号
   -v, --verbose               输出信息模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为 2
   
   myloader使用参数
   
   -d, --directory                   备份文件的文件夹
   -q, --queries-per-transaction     每次事物执行的查询数量，默认是1000
   -o, --overwrite-tables            如果要恢复的表存在，则先drop掉该表，使用该参数，需要备份时候要备份表结构
   -B, --database                    需要还原的数据库
   -e, --enable-binlog               启用还原数据的二进制日志
   -h, --host                        主机
   -u, --user                        还原的用户
   -p, --password                    密码
   -P, --port                        端口
   -S, --socket                      socket文件
   -t, --threads                     还原所使用的线程数，默认是4
   -C, --compress-protocol           压缩协议
   -V, --version                     显示版本
   -v, --verbose                     输出模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为2
   ```

2. Mysql 表级锁和行级锁

   表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；
   行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高；

   - **表级锁**

     两种锁模式：表共享读锁、表独占写锁

     兼容性：

     1. 对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
     2. 对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；

     MyISAM对表的读操作和写操作之间；当一个线程获取到写锁，只有持有锁的线程对表进行更新操作；其他线程读、写操作都会处于等待状态，知道锁被释放；

     加锁优化建议：

     1. 缩短锁定时间

        1. 尽量减少大的复杂Query，可以的话讲复杂的Query拆分为几个小的Query分布进行；
        2. 尽可能创建足够高效的索引，让查询效率更快；
        3. 合适的进行分表分库；

     2. 分离并行的操作

        

   

